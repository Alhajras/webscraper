\chapter{Introduction}
\label{chap:introduction}
\section{Motivation}

The World Wide Web (WWW) contains an enormous amount of data; this data is increasing each day rapidly. The amount of total data created and replicated is expected to grow to more than 180 zettabytes by 2025 according to Statista. The growth is expected to continue as more smartphones are more and more affordable, and more people can reach the internet. Moreover, due to the COVID-19 pandemic, more companies started offering work remotely, more shops created online stores, and more services switched to cloud-based. This change in society during the last few years has made the internet a vital part of our day-to-day life.   

Although the data is available, making a helpful meaning is a challenge. Search engines, for example, try to organize and index that information to make them easily searchable by the end user. Furthermore, collecting data can help spot competitors and have a deeper meaning in the market. Additionally, data scientists are now playing essential roles in most organizations and enterprises to understand consumer needs by collecting and analyzing data from the web.  


Although some websites provide APIs to provide organized information about their services, for example, some airline companies provide API that serves information about their flight schedules, other online shops also provide a documented API to get helpful information about their available products. This is not a guaranteed approach to gathering data, as not all websites offer an excellent documented API. For example, social media websites are reluctant to give information about their users, which is understandable. What if you would like to go through all comments and classify them as spam or not? Depending only on the assumption of having an API for each website is a fragile approach. 

Information retrieval (IR) is a term introduced in 1951 by Calvin
Mooers. It is accessing and retrieving data from a vast pool of unstructured information. One of the most practical applications of IR is to collect information from the internet; therefore, implementing a generic algorithm to gather the needed information and index them is a valid approach. Crawlers or Spiders are bots programmed to follow specific roles defined by the user to automate fetching and extracting data from the internet.  

One form of IR is a web search engine. A web search engine is a system engineered to index the internet. Users can search for articles, documents and pages by entering keywords. The search will provide a list of the most related result that matches the search query. Using the crawlers explained earlier; the engine can index the collected information and optimize the search process using different algorithms and techniques. 

Almost everyone nowadays uses Google, Bing or DuckDuckGo search engines for personal usage for research or enterprise to do market research. Search engines are so important that they make Search Engine Optimization SEO position merge and vital to any business. Harvesting, manipulating, and analysing data are essential, making information almost the new currency. 

\section{Problem Statement}

Although the available search engines are too efficient in crawling and indexing the Internet, businesses like E-commerce are primarily interested in knowing the lowest price for a specific product to understand their marketplace among their competitors. Achieving this by using Google, for example, will not solve the issue as the search directly for the product will rank the products based on some criteria predefined by the vendor Google. Those criteria can include best brands, geo-location close to the user, how well the developers optimize the SEO in the website and more. Note that the lowest price criteria are not included in page ranking. The second issue is the result format; each search engine provides a different list of results based on their implementation. This is only suitable if one is only interested in comparing prices and does not care about the various templates used on each website.\\

Search engines need to be tweaked and configured to match the domain of interest as E-commerce in the previous example and to match a specific use case like the price comparison mentioned.\\

The main problem is that businesses are often interested in only a portion of the internet that interset with their domain and expertise. Furthermore, the criteria for indexing and page ranking depend heavily on their use case and is vital to their business to take control of it and configure it as fit. 




Amount of data created, consumed, and stored 2010-2020, with forecasts to 2025
Published by 
Petroc Taylor
, Sep 8, 2022
https://www.statista.com/statistics/871513/worldwide-data-created/#:~:text=The%20total%20amount%20of%20data,to%20more%20than%20180%20zettabytes.
\section{Contributions}
\section{Chapter Overview}
