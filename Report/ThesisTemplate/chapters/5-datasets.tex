\chapter{Evaluation}
\label{chap:evaluation}
In this chapter, our objective is to assess and examine the existing search engine implementation. The evaluation process is structured into three primary segments: Crawler, Indexer, and User Experience.

\section{Testing Environment}
The evaluation procedure is significantly influenced by the specific computing device executing the tests. Displaying information about the testing machine utilized can provide enhanced clarity and facilitate meaningful comparisons.


\begin{table}[ht] 
{\footnotesize
\begin{tabular}{ P{2.5cm} ||P{11.1cm}  }      % centered columns (3 columns) 
 \hline \hline
\textbf{Operating System} & Ubuntu 22.04.3 LTS \T\B 
\\ 
\hline
\textbf{CPU} & Intel(R) Core(TM) i7-10510U @ 1.80GHz; 4 cores; 8 threads \T\B 
\\ 
\hline
\textbf{RAM} & 32GB\T\B 
\\ 
\hline
\textbf{Machine} & Lenovo ThinkPad P15s Gen 1\T\B 
\\ 
\hline \hline
    \end{tabular}
}
  \captionsetup{justification=centering,margin=2cm}
  \caption{Local machine setup}
\end{table}

\section{Crawler}  

To evaluate the web crawler, the following criteria can be employed for measurement:


{\renewcommand\labelitemi{}
\begin{itemize}
  \item \textbf{Coverage}: This metric measures the proportion of relevant web pages that the crawler can locate and fetch from the internet.

  \item \textbf{Scalability}: It evaluates the crawler's facility for efficiently scaling up to add more computing power to crawl more content.

  \item \textbf{Versatility}: Can the crawler be applied to explore diverse types of content from various websites, encompassing text, multimedia, and links?

  \item \textbf{Robustness}: The crawler's ability to adeptly manage challenging scenarios and errors.

  \item \textbf{Politeness}:  the extent to which the crawler respects the rules and policies of the web servers and avoids overloading them with requests and forbidden links.

\end{itemize}


\section{Indexer}  
\section{User Experience} 
 